{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOg1u+Xs7MslH2yk6/O4sd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brendanpshea/logic-prolog/blob/main/The_ProbabilityOfMurder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Probability of...Murder\n",
        "### A Little More Logical | Brendan Shea, PhD\n",
        "\n",
        "In this chapter, we'll exploring the role that **probability** plays in arugments and reasoning. Probability is, at its most basic, the measure of how likely something is to occur, a concept that is as pivotal in statistics as it is in the realm of detective work. In order to explore probability, we'll be enlisting the help of some famous (fictional) detectives, from the sharp Sherlock Holmes to the perceptive Nancy Drew, to see how we can use probability to weave together bits of reality into a coherent picture of truth.\n",
        "\n",
        "To get started, let's imagine that detective Adrian Monk, known keen observational skills, stands in the midst of a crime scene. He recalls that knowledge that 80% of similar crimes were committed using a particular method, he observes the same pattern at his current crime scene. This statistical insight leads Monk to a calculated conclusion: there's a high probability that these crimes are linked. Here, probability invovles concrete numbers and known frequencies. We'll later call this \"frequency-type probability.\"\n",
        "\n",
        "In contrast, let's consider the investigative approach of Velma from Scooby-Doo. In a mysterious mansion, she uncovers a concealed passage, subtly shifting the odds in favor of her hypothesis: the supposed ghost is merely a person exploiting these hidden corridors. Each clue Velma encounters – be it an unusual footprint or a specific thread of fabric – doesn’t just add to her evidence pile; it incrementally adjusts the likelihood of her theories being accurate. Her method is less about direct calculations and more about intuitively assessing how each piece of evidence modifies her hypotheses. We'll later cll this \"belief-type probability.\"\n",
        "\n",
        "For both Monk and Velma, probability is an ever-present guide. It helps them navigate through a landscape of uncertainty and ambiguity, turning each clue into a stepping stone towards the truth. This chapter will take us on a journey through the nuanced streets of probability and logic, where every clue carries its weight in the grand scheme of things.\n"
      ],
      "metadata": {
        "id": "p8-LTDh6xRmk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is Probability, Part 1: The Kolmogorov Axioms\n",
        "Tucked away in the back alleys of mathematical theory, like a cryptic clue in a detective's notebook, are the **Kolmogorov Axioms**. These axioms are the backbone of probability theory, named after the Russian mathematician Andrey Kolmogorov, who laid down the fundamental principles of probability in a rigorous mathematical way. But fear not, for these axioms are not as daunting as they might seem and can be understood without delving deep into complex mathematics.\n",
        "\n",
        "To begin, we use notation to simplify our discussion. When we talk about the probability of an event, we use the notation *Pr(Event)*. Think of it like saying, \"What are the odds of this happening?\" For example, Sherlock Holmes might calculate the probability of a suspect being at the crime scene, which we could write as *Pr(Suspect at Crime Scene)*. Similarly, when we want to talk about the probability of a hypothesis given a specific event, we use the notation *Pr(Hypothesis|Event)*. It's like asking, \"Given that this clue or event has occurred, what's the probability that my hypothesis is true?\" This is something a detective like Nancy Drew might ponder when she finds a new clue and reassesses her theories.\n",
        "\n",
        "The Kolmogorov Axioms *define* the mathematical notion of probability. They are as follows:\n",
        "\n",
        "1. **Non-negativity.** Every event E has a probability that is a non-negative number:\n",
        "  - $Pr(E) ≥ 0$.\n",
        "2. **Certainty:**  The probability of a certain (or guaranteed) event is 1. For example, the probability of \"an event E either happens or it doesn't happen\" should be 1.\n",
        "  - $Pr(E \\vee \\neg E) = 1$, where E is any event.\n",
        "3. **Additivity.** For any two muually exclusive events (events that cannot both occur at the same time), the probability of either event occurring is the sum of their individual probabilities:\n",
        "  - $Pr(A \\vee B) = Pr(A) + Pr(B)$, for mutually exclusive events A and B.\n",
        "\n",
        "The first axiom of Kolmogorov is that the probability of any event is a non-negative number. This simply means that you can't have a negative chance of something happening. It's either going to happen, or it isn't, or somewhere in between, but it's never less than zero. It's like saying, \"There's no chance that the victim committed the crime,\" which would be a probability of zero, or \"There's a certain chance that the butler did it,\" which might be a probability close to one, but never negative.\n",
        "\n",
        "The second axiom states that the probability of a certain event (one that is guaranteed to happen) is 1. In our detective story, this would be akin to saying, \"The crime definitely happened here,\" which is an absolute certainty and thus has a probability of 1.\n",
        "\n",
        "The third axiom is a bit more complex. It involves the probability of the union of two mutually exclusive events. In simple terms, if you have two events that cannot happen at the same time (like the suspect can't be both in the library and the dining room at the same moment), then the probability that either one happens is the sum of the probabilities of each happening individually. For example, if there's a 30% chance the suspect was in the library and a 40% chance they were in the dining room, and these two events are mutually exclusive, the probability of the suspect being in either location is 70%."
      ],
      "metadata": {
        "id": "gsObJnFzZQYT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some Rules for Calculating Probabilities\n",
        "\n",
        "It isn't easy to directly apply the Kolmogorov axioms to calculate probabilities. Luckily, we don't have to! Instead, we can use various derived rules (logicians might call them *theorems*) to make our lives easier. Here are a few that might come in handy.\n",
        "\n",
        "### Complement Rule\n",
        "\n",
        "The complement rule states that the probability of an event not occurring is 1 minus the probability of the event occurring.\n",
        "\n",
        "- **Complement Rule.** Pr(not E) = 1 - Pr(E), where E is any event.\n",
        "\n",
        "For example, Enola and Mycroft Holmes (Sherlock's brother and sister) are investigating a case where they know the probability of a suspect being in London is 0.65. Using the complement rule, they deduce that the probability of the suspect not being in London is 1 - 0.65 = 0.35. This calculation helps the Holmes team strategize their investigation based on the suspect's likely whereabouts."
      ],
      "metadata": {
        "id": "dkhBbNHl0-9-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running the Code in This Chapter (Optional)\n",
        "If you'd like to run the computer code in this chapter (which includes some Python functions that implement the rules of probability we are studying), you can find an interactive version of it here:\n",
        "\n",
        "https://colab.research.google.com/github/brendanpshea/logic-prolog/raw/main/The_ProbabilityOfMurder.ipynb"
      ],
      "metadata": {
        "id": "sF8elS_R2hh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# This chapter uses some helper functions\n",
        "!wget https://github.com/brendanpshea/logic-prolog/raw/main/logic_util.py\n",
        "from logic_util import *"
      ],
      "metadata": {
        "id": "d9i_OFTuv4Eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computer code to do this. Try changing the number!\n",
        "complement_rule(pr_e = 0.65)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0dekaZu379P",
        "outputId": "a0a62611-1ad3-4cca-871d-560b4ac5b5a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(not E) = 1 - P(E)\n",
            "         = 1 - 0.65\n",
            "         = 0.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Simple Addition Rule (for Mutually Exclusive Events)\n",
        "he simple addition rule applies to mutually exclusive events, meaning two events that cannot happen at the same time. The rule states that the probability of either event occurring is the sum of their individual probabilities:\n",
        "\n",
        "- **Simple Addition Rule.** Pr(A or B) = Pr(A) + Pr(B).\n",
        "\n",
        "For example, Nancy Drew is trying to determine the likelihood that a clue comes from either the attic (30% probability) or the basement (20% probability), knowing these locations cannot be involved in the clue's origin simultaneously. Applying the simple addition rule, she calculates a 50% probability (0.30 + 0.20) that the clue originates from either the attic or the basement."
      ],
      "metadata": {
        "id": "vIKvGaM26wRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some python code\n",
        "simple_addition(pr_e1 = 0.30, # attic\n",
        "                pr_e2 = 0.20) # basement"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teMOpsM87PF7",
        "outputId": "0816fb33-eee0-45fa-b7f2-6f20ae6ac713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(E1 or E2) = P(E1) + P(E2)\n",
            "            = 0.3 + 0.2\n",
            "            = 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### General Addition Rule\n",
        "The general addition rule is used when events can occur simultaneously. It states that the probability of either event A or event B occurring is the sum of their individual probabilities minus the probability of both events occurring together:\n",
        "\n",
        "- **General Addition.** Pr(A or B) = Pr(A) + Pr(B) - Pr(A and B).\n",
        "\n",
        "Suppose that Agent Scully is assessing the chances that a suspect has either a red scarf (40%) or a blue hat (50%), with a 15% chance the suspect has both. Using the general addition rule, she calculates a 75% chance (0.40 + 0.50 - 0.15) that the suspect has either a red scarf or a blue hat."
      ],
      "metadata": {
        "id": "blNWTmor9L5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "general_addition(pr_e1=0.4, # blue hat\n",
        "                 pr_e2=0.5, # red scarf\n",
        "                 pr_e1_and_e2=0.15) # both"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_ye3lhS9b8Z",
        "outputId": "ab3f967d-df23-4b2f-c70b-e1fea7161e70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(E1 or E2) = P(E1) + P(E2) - P(E1 and E2)\n",
            "            = 0.4 + 0.5 - 0.15\n",
            "            = 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple Multiplication Rule (for Independent Events)\n",
        "The simple multiplication rule applies to independent events, which are events where the occurrence of one does not affect the occurrence of the other. The rule states that the probability of both events occurring is the product of their individual probabilities:\n",
        "\n",
        "- **Simple Multiplication Rule.** Pr(A and B) = Pr(A) * Pr(B)\n",
        "\n",
        "Suppose Adrian Monk is investigating two unrelated leads: the chance that the first witness is telling the truth (70%) and the probability a second, slightly less trustworty, witness is telling the truth (50%). To deterime the probability that both are telling the truth, he would multiply 0.7 x 0.5 = 0.35. This gives the chance both leads are accurate."
      ],
      "metadata": {
        "id": "jrRQNjqnDZDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_multiplication(pr_e1=.7,  # First witness\n",
        "                      pr_e2=.5) # Second witness"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tI-feovzDy4N",
        "outputId": "ec2abe98-4771-4fc8-e405-79338a718171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(E1 and E2) = P(E1) * P(E2)\n",
            "             = 0.7 * 0.5\n",
            "             =  0.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conditional Probability\n",
        "**Conditional Probability** explores \"what ifs\" within the universe of probability, focusing on the likelihood of one event occurring under the precondition that another specific event has already taken place. It's a measure that answers questions of the form, \"Given that B has occurred, what is the chance of A happening?\" This concept is mathematically represented as Pr(A|B), signifying the probability of event A given that B is known to have occurred.\n",
        "\n",
        "The formula for calculating conditional probability is given by:\n",
        "$$\n",
        "Pr(A|B) = \\frac{Pr(A \\text{ and } B)}{Pr(B)}\n",
        "$$\n",
        "\n",
        "This equation highlights that the probability of both A and B happening together, divided by the probability of B happening, gives us the conditional probability of A given B. It's a way to refine our predictions or expectations about an event based on new information or given conditions.\n",
        "\n",
        "To bring this concept to life, let's suppose that Sherlock is investigating a case where the presence of fingerprints at a crime scene could be crucial evidence. However, the night before the investigation, it rained, potentially washing away any fingerprints. Here, Sherlock is interested in calculating the conditional probability of finding fingerprints given that it rained. If historical data or his deductive reasoning suggests that the chance of finding fingerprints after rain is 25%, then we can denote this as Pr(Fingerprints | Rain) = 0.25. This means, according to Holmes' estimation, even after rain, there's a 25% chance that fingerprints, resilient or protected enough from the weather, could still be found at the crime scene."
      ],
      "metadata": {
        "id": "T5CiefCKGFSN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Table: Sample Conditional Probabilities\n",
        "To help you get a better sense of how conditional probability works, here are some simple examples:\n",
        "\n",
        "| Conditional Probability Claim | Description |\n",
        "| --- | --- |\n",
        "| Pr(Truth \\| KnownLiar) = 0.2 | The probability of a known liar telling the truth is 20%. |\n",
        "| Pr(FingerprintMatch \\| SuspectPresent) = 0.9 | There's a 90% chance of finding a matching fingerprint if the suspect was present at the crime scene. |\n",
        "| Pr(Confession \\| Guilty) = 0.5 | If a suspect is guilty, there's a 50% probability that they will confess to the crime. |\n",
        "| Pr(PoisonDetected \\| LabTest) = 0.95 | There's a 95% chance that poison will be detected if a proper lab test is conducted. |\n",
        "| Pr(Confession \\| Guilty AND UnderPressure) = 0.85 | The probability that a guilty suspect confesses when under pressure increases to 85%. |\n",
        "| Pr(AlibiVerified \\| NOT CCTVFootage) = 0.3 | If there is no CCTV footage, the probability of an alibi being verified drops to 30%. |\n",
        "| Pr(FingerprintMatch \\| CleanedRoomOR WoreGloves) = 0.5 | There's a 50% chance of finding a matching fingerprint if the suspect cleaned the room or wore gloves, accounting for the possibility of gloves leaving no prints. |\n",
        "| Pr(NoEvidenceLeft \\| ProfessionalThief AND NightTime) = 0.95 | The probability that no evidence is left behind increases to 95% if the crime was committed by a professional thief during the night. |\n",
        "| Pr(SuspectFlees \\| Confronted AND NOT Armed) = 0.6 | If confronted and not armed, the probability that the suspect will attempt to flee increases to 60%. |\n",
        "| Pr(PoisonDetected \\| LabTest AND NOT ContaminatedSample) = 0.98 | There's a 98% chance that poison will be detected if a lab test is conducted on a sample that is not contaminated. |"
      ],
      "metadata": {
        "id": "2MJdTRlgJ7Mw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Complete Multiplication Rule (for Dependent Events)\n",
        "\n",
        "Complete Multiplication Rule applies when calculating the probability of sequential, dependent events occurring. In scenarios where one event's outcome influences another's, the probability of both events happening is the product of the first event's probability and the conditional probability of the second event given the first.\n",
        "\n",
        "$$\n",
        "Pr(A \\text{ and } B) = Pr(A) * Pr(B|A)\n",
        "$$\n",
        "\n",
        "Imagine Boba Fett tracking down two targets in the galaxy, where the capture of the first target significantly increases the chances of locating the second due to intel gathered. If the probability of capturing the first target is 70% (Pr(A) = 0.7), and this success boosts the probability of securing the second target to 80% (Pr(B|A) = 0.8), then the probability of Boba Fett capturing both targets, one after the other, can be calculated as 0.7 * 0.8 = 0.56. Thus, there's a 56% chance Boba Fett will successfully apprehend both targets, showcasing the interdependency of these events in his mission."
      ],
      "metadata": {
        "id": "bAo2YActw0Qv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "complete_multiplication(\n",
        "    pr_e1 = 0.7,\n",
        "    pr_e2_given_e1 = 0.8\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEX6IJfFyr8D",
        "outputId": "36b0e17f-3436-494f-dec7-528e970c2768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(E1 and E2) = P(E1) * P(E2|E1)\n",
            "             = 0.7 * 0.8\n",
            "             = 0.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Rules of Probability\n",
        "Here are the basic rules of probability we've discussed so far. These are all simple enough that you should be able to compute them with a simple calculator app on your phone. However, you are also welcome to try out the \"interactive\" version of this chapter, which has custom fuctions. You'll just need to click here:\n",
        "\n",
        "https://colab.research.google.com/github/brendanpshea/logic-prolog/blob/main/The_ProbabilityOfMurder.ipynb\n",
        "\n",
        "And then select \"Runtime: run all\".\n",
        "\n",
        "\n",
        "| Rule Name | Description in English | Definition | Python Function Call |\n",
        "| --- | --- | --- | --- |\n",
        "| Complement Rule | Calculates the chance of an event not happening. | `Pr(not E) = 1 - Pr(E)` | `complement_rule(pr_e)` |\n",
        "| Conditional Probability | Determines the likelihood of an event A occurring given that event B has already occurred. | `Pr(A given B) = Pr(A and B) / Pr(B)` |  |\n",
        "| Simple Addition | Finds the chance of either event happening, assuming they are mutually exclusive. | `Pr(E1 or E2) = Pr(E1) + Pr(E2)` | `simple_addition(pr_e1, pr_e2)` |\n",
        "| General Addition | Adds probabilities of two events, subtracting the overlap to avoid double counting. | `Pr(E1 or E2) = Pr(E1) + Pr(E2) - Pr(E1 and E2)` | `general_addition(pr_e1, pr_e2, pr_e1_and_e2)` |\n",
        "| Simple Multiplication | Multiplies the probabilities of two independent events to find the chance of both occurring. | `Pr(E1 and E2) = Pr(E1) * Pr(E2)` | `simple_multiplication(pr_e1, pr_e2)` |\n",
        "| Complete Multiplication | For dependent events, multiplies the probability of one event by the conditional probability of the second. | `Pr(E1 and E2) = Pr(E1) * Pr(E2 given E1)` | `complete_multiplication(pr_e1, pr_e2_given_e1)` |\n",
        "| Total Probability | Calculates overall probability of an event by considering all exclusive scenarios. | `Pr(E) = Pr(E given H1) * Pr(H1) + Pr(E given H2) * Pr(H2)` | `total_probability(pr_e_given_h1, pr_h1, pr_e_given_h2, pr_h2)` |"
      ],
      "metadata": {
        "id": "1cpeZm-r1mYs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercises\n",
        "Here are some exercises to practice the basic rules of probability.\n",
        "\n",
        "1. Detective Holmes is investigating a high-profile case and estimates the probability of the suspect being in London is 75%. What is the probability that the suspect is not in London?\n",
        "\n",
        "2.  In the case of a stolen artifact, Inspector Gadget finds that if a suspect is known to have access to the museum, the probability of them being guilty increases to 40%. Given that 30% of all suspects had access to the museum, and 12% of all suspects had access and are guilty, what is the probability a suspect is guilty given they had access?\n",
        "\n",
        "3. Sherlock Holmes is investigating a case and determines that the probability the thief took a cab away from the scene is 50% and the probability of leaving fingerprints at the scene is 20%. Assuming these events are independent, what is the probability the thief both took a cab and left fingerprints?\n",
        "\n",
        "4. Veronica Mars is trying to determine who pranked the principal. There are two suspects: Lilly and Wallace. She knows that if Lilly did it, there's a 50% chance she would use a stink bomb. If Wallace did it, there's a 30% chance of him using the same method. Given Lilly is 60% likely and Wallace 40% likely to be the prankster, what is the total probability a stink bomb was used?\n",
        "\n",
        "5. Detective Pikachu is on the trail of two separate clues regarding the location of a hidden item. He estimates a 20% chance the item is in the city park and a 15% chance it is at the local museum. Assuming these are the only two locations, what is the probability the item is at either location?\n",
        "\n",
        "6. Sam Spade is tracking two leads. The probability the first lead pans out is 60%. If the first lead is successful, the probability the second lead will also be successful increases to 70%. What is the probability both leads will be successful?\n",
        "\n",
        "7. Nancy Drew is investigating a case with two possible suspects. The probability suspect A is involved is 25%, and the probability suspect B is involved is 35%. If the probability that both A and B are involved is 10%, what is the probability that either A or B is involved?"
      ],
      "metadata": {
        "id": "C8z7UUdA210a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is Probability, Part 2: Frequencies and Beliefs\n",
        "\n",
        "In the shadowy world of probability, two distinct types emerge from the mist: frequency-type probability and belief-type probability. These two concepts, while both dealing with the likelihood of events, approach probability from different angles. Let's dive into these notions with the help of our illustrious detective squad."
      ],
      "metadata": {
        "id": "tAV3uqc-3gGF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Frequency-Type Probability: The Realm of Objective Chance\n",
        "Frequency-type probability, also known as objective chance or physical probability, is rooted in the concrete world of data and statistics. It's the type of probability that Sherlock Holmes would appreciate, as it deals with measurable, repeatable events.\n",
        "\n",
        "- Definition: **Frequency-type probability** is the relative frequency of an event occurring in a large number of trials or observations. It's the ratio of the number of times an event occurs to the total number of trials.\n",
        "\n",
        "For example, let's say that in Sherlock's vast case files, he finds that out of 100 similar crimes, 75 were committed by male perpetrators. The frequency-type probability of a crime being committed by a male, based on this data, is 75/100 = 0.75 or 75%.\n",
        "\n",
        "Mathematically, we can express frequency-type probability as:\n",
        "\n",
        "$$\n",
        "Pr(\\text{Event}) = \\frac{\\text{Number of times event occurs}}{\\text{Total number of trials}}\n",
        "$$\n",
        "\n",
        "Some other examples of frequency-type probability:\n",
        "\n",
        "1. In Agatha Christie's \"A Pocketful of Rye,\" Miss Marple investigates a series of murders involving poisoned tea. If Miss Marple discovers that out of 50 tea samples from the victim's kitchen, 5 contain the poison, the frequency-type probability of selecting a poisoned tea sample is 5/50 = 0.1 or 10%.\n",
        "2. Veronica Mars, the teenage private investigator, is tasked with uncovering a cheating scandal at her high school. If she finds that out of 500 students, 30 have been caught cheating on exams in the past year, the frequency-type probability of a student being a cheater is 30/500 = 0.06 or 6%.\n",
        "3. In \"Pokémon Detective Pikachu,\" the titular character investigates a case of missing Pokémon. If Detective Pikachu discovers that out of 100 Pokémon in the city, 15 have gone missing in the past month, the frequency-type probability of a Pokémon going missing, relative to the reference class of all Pokémon in the city, is 15/100 = 0.15 or 15%.\n",
        "\n",
        "Frequency-type probability is often used in fields like genetics, where Mendelian inheritance patterns exhibit consistent ratios, or in quality control, where the frequency of defects can be measured and predicted."
      ],
      "metadata": {
        "id": "aDHNn0PDqeTk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Belief-Type Probability: The Domain of Logical Inference\n",
        "In contrast, belief-type probability, also known as logical probability, deals with the degree of certainty or confidence in a proposition based on the available evidence and reasoning. This is the realm of deductive and inductive logic that detectives like Hercule Poirot or Nancy Drew would thrive in.\n",
        "\n",
        "- Definition: **Belief-type probability** is a measure of the rational credence or degree of belief that a proposition is true, given the available evidence and logical reasoning.\n",
        "\n",
        "For instance, suppose Nancy Drew discovers a torn piece of fabric at a crime scene that matches a suspect's jacket. This evidence increases her belief in the proposition that the suspect was present at the scene. She might assign a belief-type probability of 0.8 or 80% to this hypothesis, based on the strength of the fabric match evidence and any other corroborating or conflicting clues.\n",
        "\n",
        "Belief-type probabilities can be updated as new evidence emerges, following the principles of Bayesian inference. If Nancy later learns that the suspect has an airtight alibi, her belief in the suspect's presence at the crime scene would drastically decrease, and she would revise her belief-type probability accordingly.\n",
        "\n",
        "Some other examples of belief-type probability:\n",
        "\n",
        "1. In a case from the Marvel Universe, private investigator Jessica Jones is hired by a client who seems to be withholding information. As Jessica delves deeper into the case, she discovers inconsistencies in the client's story and uncovers evidence suggesting the client's involvement in a crime. Based on the accumulation of suspicious behavior, contradictory statements, and incriminating evidence, Jessica assigns a belief-type probability of 0.7 or 70% to the proposition that her client is guilty of the crime, given her total evidence.\n",
        "2. Inspector Morse, a brilliant detective created by Colin Dexter, investigates a case of missing jewelry. A witness reports seeing a man fitting the description of a known thief near the crime scene. Considering the reliability of the witness and the thief's past record, Morse assigns a belief-type probability of 0.6 or 60% to the hypothesis that this thief is responsible for the missing jewelry.\n",
        "3. In a hypothetical Harry Potter story, Hermione Granger is tasked with identifying a mysterious potion discovered in a hidden room at Hogwarts. After extensive research and a series of magical tests, she finds that the potion's characteristics match those of a rare, ancient healing elixir. Considering the results of her tests, the historical records she has uncovered, and the context in which the potion was found, Hermione assigns a belief-type probability of 0.9 or 90% to the hypothesis that the potion is indeed the ancient healing elixir, given her total evidence.\n",
        "\n",
        "Legal reasoning heavily relies on belief-type probability. Jurors are tasked with assessing the probability of a defendant's guilt based on the evidence presented and the arguments made by the prosecution and defense. The standard of \"beyond a reasonable doubt\" in criminal cases requires a very high belief-type probability of guilt to convict."
      ],
      "metadata": {
        "id": "B4-YsS68rcES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Putting it All Together: The Role of Probabilities in Solving Crime\n",
        "\n",
        "In the world of crime-solving, both frequency-type and belief-type probabilities play crucial roles in guiding investigations and drawing conclusions. Detectives rely on a combination of empirical data, logical reasoning, and their own intuition to navigate the complexities of a case.\n",
        "\n",
        "Frequency-type probabilities provide detectives with a baseline understanding of the likelihood of certain events or characteristics within a given reference class. For example, a detective investigating a murder might consider the frequency-type probability of the crime being committed by a stranger versus an acquaintance, based on historical crime data. This information can help guide the initial direction of the investigation and allocation of resources.\n",
        "\n",
        "On the other hand, belief-type probabilities allow detectives to update their hypotheses and theories as new evidence emerges. Each piece of evidence, whether it's a fingerprint match, a witness testimony, or a discovered motive, contributes to the detective's overall belief in the guilt or innocence of a suspect. By assigning and updating belief-type probabilities, detectives can make informed decisions about which leads to pursue and when to make an arrest.\n",
        "\n",
        "The interplay between frequency-type and belief-type probabilities is crucial in crime-solving. A detective might start with a frequency-type probability based on crime statistics, then update their belief-type probability as case-specific evidence is uncovered. For instance, if historical data suggests that 80% of similar crimes are committed by individuals with a criminal record, a detective might initially focus on suspects with prior offenses. However, if strong evidence emerges implicating a suspect with no criminal history, the detective's belief-type probability of that suspect's guilt will increase, overriding the initial frequency-type probability.\n",
        "\n",
        "Beyond crime-solving, the application of frequency-type and belief-type probabilities extends to various aspects of ordinary life and science. In medical diagnosis, doctors use frequency-type probabilities based on population data to determine the likelihood of a patient having a specific condition, given their symptoms. They then update their belief-type probability as they gather more information from tests and examinations. Similarly, in weather forecasting, meteorologists use frequency-type probabilities based on historical weather patterns and current atmospheric conditions to predict the likelihood of certain weather events, then refine their belief-type probabilities as new data becomes available.\n",
        "\n",
        "In everyday life, we constantly utilize both types of probabilities to make decisions. When choosing a restaurant, we might consider the frequency-type probability of getting a good meal based on online reviews or personal recommendations. However, our belief-type probability of enjoying a particular dish might be influenced by factors such as our mood, the appearance of the food, or the ambiance of the restaurant.\n",
        "\n",
        "The integration of frequency-type and belief-type probabilities is also essential in scientific research. Scientists use frequency-type probabilities to establish baseline expectations and develop null hypotheses, then update their belief-type probabilities as they gather experimental evidence. This process of updating beliefs based on empirical data is at the heart of the scientific method."
      ],
      "metadata": {
        "id": "-uf8qDSTuVD0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion Questions: Two Types of Probability\n",
        "1. In your own words, explain the difference between frequency-type and belief-type probabilities. Provide an example of each from your daily life.\n",
        "2. Imagine you are a detective investigating a burglary. Describe how you might use both frequency-type and belief-type probabilities to guide your investigation. How would you update your belief-type probabilities as new evidence emerges?\n",
        "3. In the medical field, doctors often use probability to make diagnoses. Discuss how frequency-type probabilities based on population data might be combined with belief-type probabilities based on a patient's specific symptoms and test results to reach a diagnosis.\n",
        "4. In the context of everyday decision-making, such as choosing a restaurant or a movie to watch, how might you use both frequency-type and belief-type probabilities to make your choice? Discuss the pros and cons of relying on each type of probability in these situations.\n",
        "5. Imagine a scenario where a frequency-type probability and a belief-type probability seem to contradict each other. For example, historical data might suggest that a certain type of crime is usually committed by a particular demographic, but specific evidence in a case points to a suspect outside that demographic. How should a detective reconcile these conflicting probabilities?\n",
        "6. In the realm of artificial intelligence and machine learning, algorithms often rely on frequency-type probabilities based on large datasets to make predictions or decisions. Discuss how the incorporation of belief-type probabilities, based on expert knowledge or case-specific evidence, might improve the accuracy and fairness of these algorithms.\n",
        "7. Probability plays a significant role in many games, from board games to sports. Choose a game you are familiar with and discuss how frequency-type and belief-type probabilities might be used to inform strategy and decision-making within the game. How might a player's understanding of these probabilities give them an advantage?"
      ],
      "metadata": {
        "id": "KzQRBHftvJ-f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Introduction to Bayes' Theorem: A Detective's Guide to Probabilistic Reasoning\n",
        "\n",
        "Imagine you're a detective, tasked with solving a complex case. You have a hunch, a hypothesis about who the culprit might be, but you need to test your theory against the evidence. This is where Bayes' Theorem comes in -- a powerful tool for updating your beliefs based on new information.\n",
        "\n",
        "At its core, Bayes' Theorem is a mathematical formula that describes how to update the probability of a hypothesis (H) given new evidence (E). It's a way to quantify the impact of evidence on your belief in a particular hypothesis. The theorem is named after Thomas Bayes, an 18th-century English statistician and minister who first developed the concept.\n",
        "\n",
        "The formula for Bayes' Theorem looks like this:\n",
        "$$\n",
        "Pr(H|E) = \\frac{Pr(H) * Pr(E|H)}{Pr(H) * Pr(E|H) + Pr(~H) * Pr(E|~H)}\n",
        "$$\n",
        "\n",
        "Don't let the mathematical notation scare you! Let's break it down term by term:\n",
        "\n",
        "-   Pr(H|E) is the probability of the hypothesis (H) being true given the evidence (E). This is what we want to calculate.\n",
        "-   Pr(H) is the prior probability of the hypothesis being true before considering the evidence. It's your initial belief in the hypothesis based on your background knowledge or intuition.\n",
        "-   Pr(E|H) is the probability of observing the evidence (E) if the hypothesis (H) is true. This is also called the likelihood of the evidence given the hypothesis.\n",
        "-   Pr(~H) is the probability of the hypothesis being false, which is equal to 1 - Pr(H).\n",
        "-   Pr(E|~H) is the probability of observing the evidence (E) if the hypothesis (H) is false.\n",
        "\n",
        "Now, let's put this into the context of a detective's work. Suppose you have a prime suspect in a murder case, but you're not entirely sure of their guilt. Your initial belief in their guilt, based on your experience and the preliminary evidence, is 60%. This is your prior probability, Pr(H).\n",
        "\n",
        "Next, you discover a piece of evidence: a witness saw someone matching your suspect's description near the crime scene at the time of the murder. You know from past cases that eyewitness testimonies are correct about 80% of the time when the suspect is guilty, Pr(E|H), and only 30% of the time when the suspect is innocent, Pr(E|~H).\n",
        "\n",
        "To update your belief in the suspect's guilt, you plug these values into Bayes' Theorem:\n"
      ],
      "metadata": {
        "id": "M_-i8eq4xxtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bayes_theorem(pr_h=.6,\n",
        "              pr_e_given_h = .8,\n",
        "              pr_e_given_not_h = .3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwXjKJIcljPH",
        "outputId": "78c6c824-8bb7-43d9-9be2-9eb51edc5328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(H|E) = (P(E|H) * P(H)) / [P(E|H) * P(H) + P(E|not H) * P(not H)]\n",
            "       = (0.8 * 0.6) / (0.8 * 0.6 + 0.3 * 0.4)\n",
            "       =  0.80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result, Pr(H|E), is the updated probability of your hypothesis (the suspect's guilt) given the new evidence (the eyewitness testimony). In this case, the probability of the suspect's guilt has increased from 60% to 80% in light of the new evidence.\n",
        "\n",
        "This is the essence of Bayesian reasoning: starting with an initial belief, observing new evidence, and updating your belief based on how well the evidence supports your hypothesis relative to alternative hypotheses. It's a process of continuously refining your beliefs as you gather more information.\n",
        "\n",
        "Bayes' Theorem has wide-ranging applications, from medical diagnosis and scientific research to machine learning and artificial intelligence. As a detective, understanding and applying Bayes' Theorem can help you navigate complex cases, weigh evidence objectively, and make more informed decisions. By thinking like a Bayesian detective, you can solve crimes with the power of probabilistic reasoning."
      ],
      "metadata": {
        "id": "lqyZ14PqyEzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bayes' Theorem and Medical Tests: Navigating Uncertainty in Diagnosis\n",
        "\n",
        "Picture yourself as a medical detective, tasked with diagnosing patients based on their symptoms and test results. Just like a detective on a case, you must weigh the evidence and update your beliefs about the likelihood of different conditions. Bayes' Theorem is a powerful tool in this process, helping you navigate the uncertainties of medical diagnosis.\n",
        "\n",
        "Let's consider a specific example: a patient takes a test for a rare disease that affects 1 in 1,000 people in the population. The test is 99% accurate, meaning it correctly identifies 99% of people who have the disease (sensitivity) and 99% of people who don't have the disease (specificity). If the patient tests positive, what is the probability that they actually have the disease?\n",
        "\n",
        "To answer this question, we can apply Bayes' Theorem. Let's define our terms:\n",
        "\n",
        "-   H: The hypothesis that the patient has the disease\n",
        "-   E: The evidence that the patient tested positive\n",
        "-   Pr(H) = 0.001 (the prior probability, or base rate, of having the disease)\n",
        "-   Pr(E|H) = 0.99 (the probability of testing positive given that the patient has the disease)\n",
        "-   Pr(~H) = 0.999 (the probability of not having the disease)\n",
        "-   Pr(E|~H) = 0.01 (the probability of testing positive given that the patient does not have the disease, which is equal to 1 - specificity)\n",
        "\n",
        "Plugging these values into Bayes' Theorem:"
      ],
      "metadata": {
        "id": "gI1kUl5F0jaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bayes_theorem(pr_h = 0.001,\n",
        "              pr_e_given_h = 0.99,\n",
        "              pr_e_given_not_h = 0.01)"
      ],
      "metadata": {
        "id": "LVAOvgZG0qv5",
        "outputId": "96040769-c6c6-4411-d5fc-c59f71b8a0f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(H|E) = (P(E|H) * P(H)) / [P(E|H) * P(H) + P(E|not H) * P(not H)]\n",
            "       = (0.99 * 0.001) / (0.99 * 0.001 + 0.01 * 0.999)\n",
            "       =  0.09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result might be surprising: even with a highly accurate test and a positive result, there's only about a 9% chance that the patient actually has the rare disease. This is because the low prior probability of having the disease (the base rate) has a significant impact on the posterior probability.\n",
        "\n",
        "This example illustrates the importance of considering base rates when interpreting medical test results. Neglecting the base rate can lead to the **base rate fallacy**, where people overestimate the probability of a condition based on a positive test result without properly accounting for the rarity of the condition in the population.\n",
        "\n",
        "The base rate fallacy can have serious consequences in medical decision-making. For example, if a doctor overestimates the probability of a patient having a disease based on a positive test result, they might recommend unnecessary treatments or procedures that carry risks and costs. On the other hand, if a doctor underestimates the probability of a disease based on a negative test result, they might fail to provide appropriate care and monitoring.\n",
        "\n",
        "To avoid the base rate fallacy and make accurate diagnoses, medical professionals (as well as patients and their advocates) must consider both the accuracy of the test and the base rate of the condition in the population. They can use Bayes' Theorem to update their beliefs about the likelihood of a condition based on the available evidence, just like a detective updating their hypothesis based on clues.\n",
        "\n",
        "Moreover, medical professionals can use Bayesian reasoning to guide further testing and investigation. If the posterior probability of a condition is still uncertain after an initial test, they can decide whether to order additional tests or gather more information to refine their diagnosis. Each new piece of evidence can be incorporated into the Bayesian framework, allowing for a continual updating of beliefs until a confident diagnosis can be made."
      ],
      "metadata": {
        "id": "XU5d86Tq08Ir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Surprising Applications of Bayes' Theorem: From Dating to Divinity and Beyond\n",
        "\n",
        "Bayes' Theorem is not just a tool for detectives and doctors; it has far-reaching applications in various aspects of life, from the everyday to the extraordinary. Let's explore some of these surprising applications and see how Bayesian reasoning can help us make better decisions and understand the world around us.\n",
        "\n",
        "1. *Determining whether to go on a date with someone.* When deciding whether to go on a date with someone, you can use Bayes' Theorem to update your belief about the likelihood of a successful relationship based on the evidence you gather. Your prior probability might be based on your past experiences with relationships or your general beliefs about compatibility. As you learn more about the person through conversations or shared experiences, you can update your probability of a successful relationship. This can help you make a more informed decision about whether to pursue a romantic connection.\n",
        "2. *Figuring out whether God exists.* The question of God's existence has puzzled philosophers and theologians for centuries. Bayes' Theorem can provide a framework for updating one's belief in the existence of God based on evidence and arguments. The prior probability of God's existence might be based on personal faith or philosophical arguments. Evidence such as the complexity of the universe, the apparent fine-tuning of physical constants, or religious experiences can be incorporated into the Bayesian framework to update the probability of God's existence. While this approach may not provide a definitive answer, it can help individuals reason about their beliefs in a more structured way.\n",
        "3. *Determining which scientific theories are true.* Science is a process of constantly updating our beliefs based on new evidence. Bayes' Theorem is a formal way of doing this, allowing scientists to compare the probability of different theories being true based on the available data. The prior probability of a theory might be based on its simplicity, elegance, or consistency with established knowledge. As new experiments are conducted and data is collected, scientists can update the probability of each theory using Bayes' Theorem. This helps the scientific community converge on the most likely explanations for natural phenomena.\n",
        "4. *The algorithms driving robots and self-driving cars.* Bayesian reasoning is at the heart of many artificial intelligence and machine learning algorithms. Robots and self-driving cars use Bayesian methods to navigate uncertain environments and make decisions based on sensor data. For example, a self-driving car might use Bayes' Theorem to update its belief about the location of pedestrians or other vehicles based on input from cameras, lidar, and other sensors. By continuously updating its probabilities, the car can make safer and more efficient decisions in real-time.\n",
        "5. *The behavior of the neural networks behind large language models.* Large language models, like chatGPT, Google Gemini, or Claude, are based on artificial neural networks that learn patterns and relationships from vast amounts of text data. These networks can be thought of as performing a form of Bayesian inference, updating their internal representations and predictions based on the input they receive. When you prompt a language model with a question or a statement, it uses its learned probabilities to generate a response that is coherent and relevant to the input. In a sense, the model is updating its \"belief\" about what words should come next based on the evidence of the prompt and its prior knowledge from training.\n",
        "\n",
        "These are just a few examples of the many surprising applications of Bayes' Theorem. From personal decision-making to the frontiers of science and technology, Bayesian reasoning provides a powerful framework for updating our beliefs in the face of uncertainty. By embracing the principles of Bayesian inference, we can make more informed choices, uncover hidden truths, and push the boundaries of what is possible.\n",
        "\n",
        "As you explore these applications further, remember that Bayes' Theorem is not a magic wand that provides definitive answers. It is a tool for reasoning about uncertainty, a way of structuring our beliefs and updating them based on evidence. Whether you're a detective, a doctor, a scientist, or simply a curious individual, understanding and applying Bayes' Theorem can help you navigate the complex web of probabilities that underlies our world."
      ],
      "metadata": {
        "id": "liUSvnON1Y-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discusion Questions\n",
        "1.  You are a detective investigating a burglary. Based on your initial assessment of the crime scene, you believe there is a 60% chance that the burglar entered through the front door. However, upon further investigation, you discover that the lock on the back door was picked, and there are muddy footprints leading from the back door to the area where the valuables were stolen. Given this new evidence, how would you update your belief about the burglar's entry point using Bayes' Theorem?\n",
        "2.  A certain disease affects 1 in 10,000 people. A test for this disease has a 95% accuracy rate, meaning it correctly identifies 95% of people who have the disease and 95% of people who don't have the disease. If a person tests positive for the disease, what is the probability that they actually have the disease? Use Bayes' Theorem to calculate the updated probability.\n",
        "3.  You are considering whether to go on a date with someone you met online. Based on their profile and your prior experiences with online dating, you initially believe there is a 30% chance that you will have a good connection in person. After exchanging a few messages, you discover that you have several shared interests and values. Given this new information, how would you update your belief about the likelihood of a successful date using Bayes' Theorem?\n",
        "4.  In Bayesian reasoning, prior probabilities play a crucial role in determining the posterior probability of a hypothesis. How do our prior beliefs influence the way we interpret new evidence? Can you think of examples where strong prior beliefs might lead to biased or irrational conclusions, even in the face of contradictory evidence?\n",
        "5.  The concept of updating beliefs based on new evidence is central to Bayesian reasoning. How might this approach be useful in everyday life, beyond the realm of detective work or scientific inquiry? Can you think of situations where you have updated your beliefs based on new information, and how did this process affect your decision-making?\n",
        "6.  Bayesian reasoning has been applied to various fields, from artificial intelligence and machine learning to philosophy and theology. What do you think are some of the most promising or interesting applications of Bayesian methods? How might the widespread adoption of Bayesian reasoning impact society and our understanding of the world?\n",
        "7.  Bayesian reasoning is often used to compare and evaluate competing hypotheses or models. In your opinion, what makes a hypothesis or model more likely to be true from a Bayesian perspective? How might factors like simplicity, explanatory power, or consistency with prior knowledge influence the probability of a hypothesis?"
      ],
      "metadata": {
        "id": "rxTP8uOp26ir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Glossary\n",
        "| Term | Definition |\n",
        "| --- | --- |\n",
        "| Probability | A numerical measure of the likelihood that an event will occur, expressed as a value between 0 and 1, where 0 indicates impossibility and 1 indicates certainty. |\n",
        "| Complement Rule | States that the probability of an event not occurring is equal to 1 minus the probability of the event occurring. Mathematically, for an event A, P(A') = 1 - P(A). |\n",
        "| Simple Addition Rule (for mutually exclusive events) | States that the probability of either of two mutually exclusive events occurring is equal to the sum of their individual probabilities. Mathematically, for mutually exclusive events A and B, P(A or B) = P(A) + P(B). |\n",
        "| General Addition Rule | States that the probability of at least one of two events occurring is equal to the sum of their individual probabilities minus the probability of both events occurring simultaneously. Mathematically, for events A and B, P(A or B) = P(A) + P(B) - P(A and B). |\n",
        "| Simple Multiplication Rule (for independent events) | States that the probability of two independent events both occurring is equal to the product of their individual probabilities. Mathematically, for independent events A and B, P(A and B) = P(A) × P(B). |\n",
        "| General Multiplication Rule | States that the probability of two events both occurring is equal to the probability of one event occurring multiplied by the conditional probability of the second event occurring given that the first event has occurred. Mathematically, for events A and B, P(A and B) = P(A) × P(B|A). |\n",
        "| Conditional Probability | The probability of an event occurring given that another event has already occurred. Mathematically, for events A and B, the conditional probability of A given B is denoted as P(A|B) and is calculated as P(A|B) = P(A and B) / P(B), provided that P(B) > 0. |\n",
        "| Rule of Total Probability | A formula that expresses the total probability of an event as the sum of the products of the conditional probabilities of the event given each possible outcome of another event and the probabilities of those outcomes. Mathematically, if B1, B2, ..., Bn are mutually exclusive and exhaustive events, then for any event A, P(A) = P(A|B1) × P(B1) + P(A|B2) × P(B2) + ... + P(A|Bn) × P(Bn). |\n",
        "| Frequency-type probability | An interpretation of probability based on the relative frequency of an event occurring in a large number of trials or observations. |\n",
        "| Belief-type probability | An interpretation of probability based on an individual's subjective belief or confidence in the likelihood of an event occurring, often informed by prior knowledge or experience. |\n",
        "| Bayes Theorem | A formula that describes the relationship between conditional probabilities and enables the updating of probabilities based on new evidence or information. Mathematically, for events A and B, Bayes Theorem states that P(A|B) = (P(B|A) × P(A)) / P(B). |\n",
        "| Prior Probability - Pr(H) | The initial probability of a hypothesis (H) being true before considering any evidence or data. |\n",
        "| Posterior Probability - Pr(H\\|E) | The updated probability of a hypothesis (H) being true after considering the evidence (E) or data. |\n",
        "| Likelihood - Pr(E\\|H) | The probability of observing the evidence (E) given that the hypothesis (H) is true. |\n",
        "| Pr(E\\| not H) | The probability of observing the evidence (E) given that the hypothesis (H) is not true. |"
      ],
      "metadata": {
        "id": "kRp2z7sd9eOb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LUo6zhcv0iWN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
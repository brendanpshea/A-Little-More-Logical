{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfsGvkUpJAV81drUblrMA+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brendanpshea/logic-prolog/blob/main/The_ProbabilityOfMurder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECoZc0tFkjnp"
      },
      "outputs": [],
      "source": [
        "def validate_probabilities(*probs):\n",
        "  \"\"\"Validates that each probability value is between 0 and 1.\"\"\"\n",
        "  if any(not 0 <= p <= 1 for p in probs):\n",
        "    raise ValueError(\"Probabilities must be between 0 and 1.\")\n",
        "\n",
        "def complement_rule(pr_e):\n",
        "    \"\"\"Calculates the probability that event E doesn't occur.\"\"\"\n",
        "    validate_probabilities(pr_e)\n",
        "    complement = 1 - pr_e\n",
        "    return f\"P(¬E) = 1 - P(E) = 1 - {pr_e} = {complement}\"\n",
        "\n",
        "def conditional_probability(pr_a, pr_b, pr_a_and_b):\n",
        "    \"\"\"Calcutates the probability of A, given that B is true\"\"\"\n",
        "    validate_probabilities(pr_a, pr_b, pr_a_and_b)\n",
        "    if pr_b == 0:\n",
        "        raise ValueError(\"P(B) cannot be 0.\")\n",
        "    pr_a_given_b = pr_a_and_b / pr_b\n",
        "    return f\"P(A|B) = P(A ∩ B) / P(B) = {pr_a_and_b} / {pr_b} = {pr_a_given_b}\"\n",
        "\n",
        "def complete_addition(pr_e1, pr_e2, pr_e1_and_e2):\n",
        "    \"\"\"Calculates the probability either E1 or E2 occur.\"\"\"\n",
        "    validate_probabilities(pr_e1, pr_e2, pr_e1_and_e2)\n",
        "    result = pr_e1 + pr_e2 - pr_e1_and_e2\n",
        "    return f\"P(E1 ∪ E2) = P(E1) + P(E2) - P(E1 ∩ E2) = {pr_e1} + {pr_e2} - {pr_e1_and_e2} = {result}\"\n",
        "\n",
        "def simple_multiplication(pr_e1, pr_e2):\n",
        "    \"\"\"Calculates the probability both E1 and E2 occur (assumes independence).\"\"\"\n",
        "    validate_probabilities(pr_e1, pr_e2)\n",
        "    result = pr_e1 * pr_e2\n",
        "    return f\"P(E1 ∩ E2) = P(E1) * P(E2) = {pr_e1} * {pr_e2} = {result}\"\n",
        "\n",
        "def complete_multiplication(pr_e1, pr_e2, pr_e1_given_e2):\n",
        "    \"\"\"Calculates the probability bott E1 and E2 occur (may not be indpendent).\"\"\"\n",
        "    validate_probabilities(pr_e1, pr_e2, pr_e1_given_e2)\n",
        "    result = pr_e1_given_e2 * pr_e2\n",
        "    return f\"P(E1 ∩ E2) = P(E1|E2) * P(E2) = {pr_e1_given_e2} * {pr_e2} = {result}\"\n",
        "\n",
        "def total_probability(pr_e_given_h1, pr_h1, pr_e_given_h2, pr_h2):\n",
        "    \"\"\"\n",
        "    Calculates the total probability of an event E given two exclusive hypotheses H1 and H2.\n",
        "    \"\"\"\n",
        "    validate_probabilities(pr_e_given_h1, pr_h1, pr_e_given_h2, pr_h2)\n",
        "    pr_e = pr_e_given_h1 * pr_h1 + pr_e_given_h2 * pr_h2\n",
        "    return (f\"P(E) = P(E|H1) * P(H1) + P(E|H2) * P(H2)\\n\"\n",
        "            f\"     = {pr_e_given_h1} * {pr_h1} + {pr_e_given_h2} * {pr_h2}\\n\"\n",
        "            f\"     = {pr_e}\")\n",
        "def bayes_theorem(p_h, pr_e_given_h, pr_e_given_not_h):\n",
        "    \"\"\"Calculates probability of a hypotheses being true, given some evidence.\"\"\"\n",
        "    validate_probabilities(p_h, pr_e_given_h, pr_e_given_not_h)\n",
        "    p_not_h = 1 - p_h\n",
        "    pr_e = pr_e_given_h * p_h + pr_e_given_not_h * p_not_h\n",
        "    p_h_given_e = (pr_e_given_h * p_h) / pr_e\n",
        "    print(f\"P(H|E) = (P(E|H) * P(H)) / [P(E|H) * P(H) + P(E|not H) * P(not H)]\")\n",
        "    print(f\"       = ({pr_e_given_h} * {p_h}) / ({pr_e_given_h} * {p_h} + {pr_e_given_not_h} * {p_not_h})\")\n",
        "    print(f\"       = {round(p_h_given_e,2)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Probability of...Murder\n",
        "In this chapter, we'll exploring the role that **probability** plays in arugments and reasoning. Probability is, at its most basic, the measure of how likely something is to occur, a concept that is as pivotal in statistics as it is in the realm of detective work. In order to explore probability, we'll be enlisting the help of some famous (fictional) detectives, from the sharp Sherlock Holmes to the perceptive Nancy Drew, to see how we can use probability to weave together bits of reality into a coherent picture of truth.\n",
        "\n",
        "To get started, let's imagine that detective Adrian Monk, known keen observational skills, stands in the midst of a crime scene. He recalls that knowledge that 80% of similar crimes were committed using a particular method, he observes the same pattern at his current crime scene. This statistical insight leads Monk to a calculated conclusion: there's a high probability that these crimes are linked. Here, probability invovles concrete numbers and known frequencies. We'll later call this \"frequency-type probability.\"\n",
        "\n",
        "In contrast, let's consider the investigative approach of Velma from Scooby-Doo. In a mysterious mansion, she uncovers a concealed passage, subtly shifting the odds in favor of her hypothesis: the supposed ghost is merely a person exploiting these hidden corridors. Each clue Velma encounters – be it an unusual footprint or a specific thread of fabric – doesn’t just add to her evidence pile; it incrementally adjusts the likelihood of her theories being accurate. Her method is less about direct calculations and more about intuitively assessing how each piece of evidence modifies her hypotheses.\n",
        "\n",
        "For both Monk and Velma, probability is an ever-present guide. It helps them navigate through a landscape of uncertainty and ambiguity, turning each clue into a stepping stone towards the truth. This chapter will take us on a journey through the nuanced streets of probability and logic, where every clue carries its weight in the grand scheme of things.\n"
      ],
      "metadata": {
        "id": "p8-LTDh6xRmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bayes_theorem(p_h = 0.5,\n",
        "              pr_e_given_h = .9,\n",
        "              pr_e_given_not_h = .2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwXjKJIcljPH",
        "outputId": "79db9d11-1c08-4703-8810-6e3ce9a74696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(H|E) = (P(E|H) * P(H)) / [P(E|H) * P(H) + P(E|not H) * P(not H)]\n",
            "       = (0.9 * 0.5) / (0.9 * 0.5 + 0.2 * 0.5)\n",
            "       = 0.82\n"
          ]
        }
      ]
    }
  ]
}